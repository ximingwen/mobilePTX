{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93331aca-0e78-4686-85c6-c8c2eb583f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sparse_coding_torch.BamcPreprocessor import BamcPreprocessor\n",
    "from sparse_coding_torch.video_loader import MinMaxScaler\n",
    "from sparse_coding_torch.video_loader import VideoGrayScaler\n",
    "from sparse_coding_torch.video_loader import VideoLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf94800-fa40-4151-966b-b72082e4606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/shared_data/bamc_data\"\n",
    "\n",
    "transforms = torchvision.transforms.Compose([VideoGrayScaler(),\n",
    "                                             MinMaxScaler(0, 255),\n",
    "                                             BamcPreprocessor(),\n",
    "                                             # torchvision.transforms.Resize(size=(height, width))\n",
    "                                            ])\n",
    "dataset = VideoLoader(video_path, transform=transforms, num_frames=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c212ff21-3229-4df7-b792-f6e839759c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/62 [00:00<?, ?it/s]/home/cm3786@drexel.edu/.pyenv/versions/3.9.6/envs/jupyter3.9.6/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 62/62 [02:46<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "destination_path = \"/shared_data/bamc_data_preprocessed\"\n",
    "\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    label, video, filename = dataset[idx]\n",
    "    \n",
    "    label_path = destination_path + \"/\" + label\n",
    "    Path(label_path).mkdir(parents=True, exist_ok=True)  \n",
    "    \n",
    "    video = video.swapaxes(0, 1).swapaxes(1, 2).swapaxes(2, 3) * 255\n",
    "    video = video.byte().expand(-1, -1, -1, 3)\n",
    "    \n",
    "    torchvision.io.write_video(label_path + \"/\" + filename, video, fps=20, video_codec='h264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ad7e0-2ce1-4e13-9bc0-83fdb36e6cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chris-py3.9.6",
   "language": "python",
   "name": "chris-py3.9.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
